{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T14:09:38.169631800Z",
     "start_time": "2024-06-05T14:09:37.289473400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T14:09:41.005100400Z",
     "start_time": "2024-06-05T14:09:40.999306900Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset_withfeatures_pandas(dataset_path):\n",
    "    \"\"\"This function loads CSV datasets using the read_csv method of the pandas library.\n",
    "    The CSV is epxected to be comma-separated, while separate examples are separated by new line.\n",
    "    All but the last column are expected to be features, the last columns is parsed as output variable.\"\"\"\n",
    "    df = pd.read_csv(dataset_path)\n",
    "\n",
    "    X = df.iloc[:, :-1].to_numpy()\n",
    "    y = df.iloc[:, -1].to_numpy()\n",
    "\n",
    "    feature_names = df.iloc[:, :-1].columns.tolist()\n",
    "\n",
    "    return X, y, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T14:06:59.560612900Z",
     "start_time": "2024-06-05T14:06:59.547030700Z"
    }
   },
   "outputs": [],
   "source": [
    "def kfold_crossval(classifier, X, y, k=10):\n",
    "    \"\"\"Function to evaluate a scikit learn model in 10-fold shuffled\n",
    "    split cross validation. \n",
    "    \"\"\"\n",
    "    # TODO:\n",
    "    # Estimate model performance for given classifier\n",
    "    # Evaluate on k-fold split the validation and train error\n",
    "        # HINT: we are working with classes and classification data\n",
    "        # What does this mean for the cross validation method?\n",
    "    # Return metric for model selection\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T14:07:00.977058400Z",
     "start_time": "2024-06-05T14:07:00.968132400Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_and_plot_classifer_hyperparams(X, y, classifier, hyperparam_name, hyperparam_values):\n",
    "    \"\"\"Tests different classifiers for different values of a hyper parameter given to the function.\"\"\"\n",
    "\n",
    "    # TODO:\n",
    "    # This is how I have done it, this can possibly be split into two functions\n",
    "    # Carry out accuracy estimation (crossval) on models with different hyperparams\n",
    "    # Plot results against hyperparams\n",
    "    # Don't forget: there are 2 things you need to plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset = load_dataset_withfeatures_pandas(\"adult_sourcedata.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T14:09:43.234068300Z",
     "start_time": "2024-06-05T14:09:43.146276200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<48842x74 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x28523 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x15 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x123 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x99 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x96 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>\n",
      " <48842x42 sparse matrix of type '<class 'numpy.float64'>'\n",
      " \twith 48842 stored elements in Compressed Sparse Row format>]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Apply the OneHotEncoder to each column\n",
    "encoded_columns = []\n",
    "data = dataset[0]\n",
    "for i in range(data.shape[1]):\n",
    "    column_data = data[:, i].reshape(-1, 1)  # Reshape to 2D array for encoder\n",
    "    encoded_col = encoder.fit_transform(column_data)\n",
    "    encoded_columns.append(encoded_col)\n",
    "# Concatenate all the encoded columns horizontally\n",
    "encoded_data = np.hstack(encoded_columns)\n",
    "\n",
    "print(encoded_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T14:09:50.081042Z",
     "start_time": "2024-06-05T14:09:49.922554400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<48842x74 sparse matrix of type '<class 'numpy.float64'>'\n\twith 48842 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T14:10:15.497036500Z",
     "start_time": "2024-06-05T14:10:15.487278Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([38, 'Private', 89814, 'HS-grad', 9, 'Married-civ-spouse',\n       'Farming-fishing', 'Husband', 'White', 'Male', 0, 0, 50,\n       'United-States'], dtype=object)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T14:00:04.841152200Z",
     "start_time": "2024-06-05T14:00:04.833966Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "[]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# load data\n",
    "# 1.\n",
    "# for different max_depth\n",
    "    # train decision tree\n",
    "    # find out how it performs\n",
    "# plot what you found (max_depth influence)\n",
    "# 2.\n",
    "# for different max_depth\n",
    "    # train random forest classifier\n",
    "    # find out how it performs\n",
    "# plot what you found (max_depth influence)\n",
    "# calc accuracy\n",
    "# 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_teaching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fc36ab0d55a6a226ae882655424b723ba299a7c7e2b24a1d4fe088de8ed7471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
